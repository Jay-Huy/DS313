{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bec9f6b9",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d840a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Failed to find CUDA.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\huy\\anaconda3\\envs\\vllm_env\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(149466760, 149466760, 141578888)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from asr_model import ASRModel\n",
    "\n",
    "a, b, c = ASRModel(model_dim=768, mode = 'A').to('cuda'), ASRModel(model_dim=768, mode = 'B').to('cuda'), ASRModel(model_dim=768, mode = 'C').to('cuda')\n",
    "a.params, b.params, c.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af4f9fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "audio_features = torch.randn(10, 20, 768).to('cuda')  # Example input tensor (seq_len, batch_size, acoustic_input_dim)\n",
    "input_ids = torch.randint(0, 21128, (10, 35)).long().to('cuda')\n",
    "attention_mask = torch.ones(10, 35).to('cuda')  # Example attention mask (batch_size, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9baf5385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 35]), torch.Size([10, 20, 768]), torch.Size([10, 35]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids.shape, audio_features.shape, attention_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29d8bff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 35, 21128])\n"
     ]
    }
   ],
   "source": [
    "a_lala = a(input_ids = input_ids,\n",
    "           attention_mask = None,\n",
    "           audio_features = audio_features)\n",
    "print(a_lala.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f260e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 35, 21128])\n"
     ]
    }
   ],
   "source": [
    "b_lala = b(input_ids = input_ids,\n",
    "           attention_mask = None,\n",
    "           audio_features = audio_features)\n",
    "print(b_lala.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e2f1023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 35, 21128])\n"
     ]
    }
   ],
   "source": [
    "c_lala = c(input_ids = input_ids,\n",
    "           attention_mask = None,\n",
    "           audio_features = audio_features)\n",
    "print(c_lala.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fcc1be",
   "metadata": {},
   "source": [
    "# Train Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f3dc4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tuleh\\anaconda3\\envs\\myenv\\Lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\tuleh\\.cache\\huggingface\\hub\\models--bert-base-chinese. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\tuleh\\anaconda3\\envs\\myenv\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: ['而 对 楼市 成交 抑制 作用 最 大 的 限 购', '也 成为 地方 政府 的 眼中 钉', '自 六月 底 呼和浩特 市 率先 宣布 取消 限 购 后', '各地 政府 便 纷纷 跟进']\n",
      "Tokenized text: ['[CLS] 而 对 楼 市 成 交 抑 制 作 用 最 大 的 限 购 [SEP] [PAD] [PAD] [PAD]', '[CLS] 也 成 为 地 方 政 府 的 眼 中 钉 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] 自 六 月 底 呼 和 浩 特 市 率 先 宣 布 取 消 限 购 后 [SEP]', '[CLS] 各 地 政 府 便 纷 纷 跟 进 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from asr_model import ASRModel\n",
    "from evaluate import load\n",
    "cer = load(\"cer\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-chinese\")\n",
    "model = ASRModel(model_dim=768, mode='A').to(device)\n",
    "\n",
    "# Tokenzier\n",
    "bos_token = tokenizer.cls_token_id\n",
    "eos_token = tokenizer.sep_token_id\n",
    "pad_token = tokenizer.pad_token_id\n",
    "\n",
    "# Example text input and features\n",
    "text = [\"而 对 楼市 成交 抑制 作用 最 大 的 限 购\", \"也 成为 地方 政府 的 眼中 钉\", \"自 六月 底 呼和浩特 市 率先 宣布 取消 限 购 后\", \"各地 政府 便 纷纷 跟进\"]\n",
    "input_ids = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "decoded_text = tokenizer.batch_decode(input_ids[\"input_ids\"])\n",
    "print(f'Original text: {text}')\n",
    "print(f'Tokenized text: {decoded_text}')\n",
    "\n",
    "downsampled_features = torch.rand(4, 128, 205, 80) # (B, C, T, F) -> (B, T, C*F)\n",
    "batch = {\n",
    "    'input_ids': input_ids.input_ids,\n",
    "    'attention_mask': input_ids.attention_mask,\n",
    "    'downsampled_features': downsampled_features,\n",
    "}\n",
    "for k in batch:\n",
    "    batch[k] = batch[k].to(device=device, non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20f62863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['而 对 楼 市 成 交 抑 制 作 用 最 大 的 限 购 [SEP] [PAD] [PAD] [PAD] [PAD]',\n",
       " '也 成 为 地 方 政 府 的 眼 中 钉 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]',\n",
       " '自 六 月 底 呼 和 浩 特 市 率 先 宣 布 取 消 限 购 后 [SEP] [PAD]',\n",
       " '各 地 政 府 便 纷 纷 跟 进 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = batch['input_ids']  # Batch_size, seq_length\n",
    "downsampled_features = batch['downsampled_features']  # Batch_size, seq_length, feature_dim\n",
    "attention_mask = batch['attention_mask']  # Batch_size, seq_length\n",
    "\n",
    "shifted_left_outputs = torch.cat([input_ids[:, 1:], torch.full((input_ids.size(0), 1), tokenizer.pad_token_id, dtype=torch.long, device=device)], dim=1)\n",
    "tokenizer.batch_decode(shifted_left_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74310df4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 20, 21128])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B, C, T, F = downsampled_features.shape\n",
    "outputs = model(input_ids, attention_mask, downsampled_features.view(B, T, C*F))  # Batch_size, seq_length, vocab_size\n",
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d689cce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute CER and loss\n",
    "ids_prediction = outputs.argmax(dim=-1)  # Batch_size, seq_length\n",
    "predictions = tokenizer.batch_decode(ids_prediction, skip_special_tokens=True)  # Batch_size\n",
    "references = tokenizer.batch_decode(shifted_left_outputs, skip_special_tokens=True)  # Batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c5d97a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "References: ['而 对 楼 市 成 交 抑 制 作 用 最 大 的 限 购', '也 成 为 地 方 政 府 的 眼 中 钉', '自 六 月 底 呼 和 浩 特 市 率 先 宣 布 取 消 限 购 后', '各 地 政 府 便 纷 纷 跟 进']\n"
     ]
    }
   ],
   "source": [
    "print(f'References: {references}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04b8160b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: ['ex 闌 脳 筑晝還綑弈詡 鲑 a灬 helpapp 驍端 笆窗 錳 间ien', '##餡澆 蚤箍奘兰 蜆過崛 辻 畳med 1907锏锏 喟 焘 による 铿 第', '##しています 鈕 fx娄鋅 汶 繩 xddd丐 害将 惘撮訶のは realᅣvr 畳yo', '##琳尻 贻 蒞 捍 co2 淌 电槓 饰骁 飘炼 剣靴淼 hard 间 庠挾']\n"
     ]
    }
   ],
   "source": [
    "print(f'Predictions: {predictions}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3687e6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cer_score = cer.compute(predictions=predictions, references=references)\n",
    "cer_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "051ba5d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 20, 21128]), torch.Size([4, 20]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape, shifted_left_outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cd99dcfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huy\\AppData\\Local\\Temp\\ipykernel_16536\\4162233661.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  cer_score = torch.tensor(cer_score, dtype=torch.float32, device=outputs.device)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(10.0796, device='cuda:0', grad_fn=<NllLoss2DBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def loss_fn(outputs, labels, cer_score, criterion, gamma=1.0, ignore_index=0):\n",
    "    \"\"\"\n",
    "    Compute the weighted loss for the Decoder using alpha weights based on CER.\n",
    "\n",
    "    Args:\n",
    "        outputs (torch.Tensor): Model predictions of shape (batch_size, seq_length, vocab_size).\n",
    "        labels (torch.Tensor): Ground truth labels of shape (batch_size, seq_length).\n",
    "        cer_score (float): Character Error Rate (CER) for the Decoder.\n",
    "        gamma (float): Hyperparameter to control the influence of CER in alpha computation.\n",
    "        ignore_index (int): The padding value in the labels to be ignored in the loss calculation.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: The computed weighted loss.\n",
    "    \"\"\"\n",
    "    # Ensure cer_score is a tensor\n",
    "    cer_score = torch.tensor(cer_score, dtype=torch.float32, device=outputs.device)\n",
    "\n",
    "    # Compute alpha weight based on CER\n",
    "    alpha = -(cer_score ** gamma) * torch.log(1 - cer_score + 1e-8)  # Add epsilon to avoid log(0)\n",
    "\n",
    "    # Compute the base loss\n",
    "    base_loss = criterion(outputs.mT, labels)  # Flatten outputs and labels\n",
    "    if base_loss < 1:\n",
    "        try: \n",
    "            alpha = -(cer_score ** gamma) * torch.log(1 - cer_score + 1e-8)  # Add epsilon to avoid log(0)\n",
    "            base_loss = base_loss * alpha  # Apply alpha weight to the loss\n",
    "        except:\n",
    "            base_loss = base_loss # Avoid cer_score is bigger than 1\n",
    "\n",
    "    return base_loss\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss(ignore_index=pad_token)\n",
    "loss = loss_fn(outputs, shifted_left_outputs, cer_score, criterion)\n",
    "loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
