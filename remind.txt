- Check lại xem audio có mask hay không

- Các việc cần làm:
+ Chạy DataLoader để xem như thế nào (Ngày mai)
+ Code Train function, Infer Function, Evaluation Function (T5 đi với Mthu, Lưu ý cái cơ chế shifted right của nó)
+ Chạy thử 1 structure để xem kết quả (T6 và T7, CN check kết quả)

---------------10/4/2025 Note----------------
- Check DataLoader
- Check cơ chế shifted-right-input có đúng hay chưa
- Code cơ chế tính weight và loss của model
- Phải kiểm tra lại kĩ càng input_ids, shifted_right_outputs, outputs, predictions (nếu không thì tính loss sẽ bị sai)
- Check 1 batch chạy bao nhiêu lâu để tính thời gian train 
- Check lại logic của loss_fn và cer xem đã đúng chưa

---------------11/4/2025 Note----------------
- Init Data + Tokneizer
- Init Model (Done)
- Init Optimizer, Criterion, Scheduler, ...
- Train function, Infer function


---------------Dataloader Note----------------
A. 1 Batch của DataLoader cần có các item là: transcript_paths, wav_paths, transcripts, downsampled_features, tokenized_transcripts
Kiểu return trong collate_fn sẽ như là:
return {
    'transcript_paths': transcript_paths,
    'wav_paths': wav_paths,
    'transcripts': transcripts,
    'downsampled_features': downsampled_features,
    'tokenized_transcripts': tokenized_transcripts
}

B. Không cần tạo ra bộ vocab và tokenizer riêng, mình xài cái này: AutoTokenizer.from_pretrained("bert-base-chinese")
Ông muốn padding hay eos_token hay bos_token gì thì cũng xài của tokenizer luôn. 
Nhưng mà ông load ở ngoài rồi truyền vào dataset nha, đừng load trong dataset tại lúc train vẫn cần gọi lại tokenizer.

C. Trích xuất đặc trưng luôn trong hàm collate_fn : 
Kiểu cái downsampled_features là cái mà mình đã làm xong xuôi hết luôn rồi á, nó chỉ cần truyền vào và train thôi, không cần chạy gì thêm cho nó. 
Làm vậy thì code của mình sẽ sạch hơn á ông. Còn lại ông muốn để shape dạng (B, C, T, F) hay (B, T, C*f) cũng được

---------------15/4/2025 Note----------------
- Model bằng Adam đã FAILED -> Shifted Left Output 

- Đang train model bằng AdamW - Thay Chinese Bert thành Chinese T5 (chỉ trong 2-3 epoch và xem kết quả)

- Có thể sẽ phải code lại model:
    + CNN-AcousticEncoder -> Wave2Vec or Speech2Text
    + Contextual Encoder -> (Check lại các ASR model, hoặc sử dụng của pretrained-model)
    + Deocder -> T5
    + Check lại cả cách tính loss. 

---------------Task 21/4/2025----------------
- Bởi vì việc train model có thể sẽ FAILED, nên yêu cầu 2 bạn còn lại đi survey lại từ đầu. Yêu cầu cho 1 bài survey là:
    + Phải có sẵn code (QUAN TRỌNG).
    + Khi tìm ra phải thử xem code có chạy dc hay không, đừng chỉ gửi cái repo lên và nói đã tìm thấy rồi (QUAN TRỌNG).
    + Phải kiểm tra thông tin dataset (có bao nhiêu ở 3 file train, test, dev; có down dc hay không).
    + Kiểm tra thông tin model xem model có size là bao nhiêu ().
    + Kiểm tra xem nếu chạy 1 batch thì tốn bao lâu -> Từ đó ước lượng thời gian train.

- Hỏi team xem t3 tsau có đi học được không, bởi vì nghe báo cáo trực tiếp thì oke hơn.

Việc của Huy: Check lại Model và refer từ SpeechText
Việc của Kiệt: Chạy SpeechText
Việc của Tường và Quân: Ở trên

---------------Not 16/4/2025----------------
- Check lại cơ chế tokenizer của T5
- Train 2 Epoch.