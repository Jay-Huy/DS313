{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113492a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "from asr_model import ASRModel\n",
    "from dataset import AISHELL1Dataset, PadCollate, PretrainedVGGExtractor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0544aec",
   "metadata": {},
   "source": [
    "# Init Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2cc5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define arguments\n",
    "TRANSCRIPT_PATH = \"path/to/transcript.txt\"  # Replace with your transcript path\n",
    "WAV_PATH = \"path/to/wav\"  # Replace with your wav directory path\n",
    "CHECKPOINT_PATH = \"path/to/checkpoint.pth\"  # Replace with your checkpoint path\n",
    "STRUCTURE = \"A\"  # Model structure (e.g., 'A', 'B', 'C')\n",
    "BATCH_SIZE = 4  # Batch size for the demo\n",
    "NUM_WORKERS = 2  # Number of workers for DataLoader\n",
    "TOKENIZER_NAME = \"bert-base-chinese\"  # Tokenizer name\n",
    "RESHAPE_VGG_OUTPUT = True  # Whether to reshape VGG output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612b263b",
   "metadata": {},
   "source": [
    "# Load Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91a06f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_NAME)\n",
    "PAD_IDX = tokenizer.pad_token_id\n",
    "\n",
    "# Initialize VGG Feature Extractor\n",
    "vgg_model = PretrainedVGGExtractor(freeze_features=True)\n",
    "\n",
    "# Initialize PadCollate\n",
    "pad_collate_instance = PadCollate(\n",
    "    pad_idx=PAD_IDX,\n",
    "    vgg_model=vgg_model,\n",
    "    tokenizer=tokenizer,\n",
    "    reshape_features=RESHAPE_VGG_OUTPUT\n",
    ")\n",
    "\n",
    "# Create Dataset and Dataloader\n",
    "test_dataset = AISHELL1Dataset(\n",
    "    TRANSCRIPT_PATH, WAV_PATH, split='test'\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    collate_fn=pad_collate_instance,\n",
    "    num_workers=NUM_WORKERS\n",
    ")\n",
    "\n",
    "print(f\"Test Dataloader Length: {len(test_dataloader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213e2649",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a690d44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize model\n",
    "model = ASRModel(model_dim=768, mode=STRUCTURE).to(device)\n",
    "\n",
    "# Load checkpoint\n",
    "checkpoint = torch.load(CHECKPOINT_PATH, map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "print(f\"Checkpoint loaded from {CHECKPOINT_PATH}\")\n",
    "\n",
    "# Show model architecture\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6708fcac",
   "metadata": {},
   "source": [
    "# Show Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879ba069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get one batch from the dataloader\n",
    "batch = next(iter(test_dataloader))\n",
    "print(\"Batch Keys:\")\n",
    "print(f'Text: {batch['original_transcript']}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f658b568",
   "metadata": {},
   "source": [
    "# Forward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40d4178",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "cer = load(\"cer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4581889",
   "metadata": {},
   "source": [
    "## Teacher Forcing Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d67330f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform forward pass using teacher_forcing_generate_tokens\n",
    "from utils import teacher_forcing_generate_tokens\n",
    "\n",
    "# Move batch to device\n",
    "batch = {key: value.to(device) if isinstance(value, torch.Tensor) else value for key, value in batch.items()}\n",
    "\n",
    "# Compute predictions and CER score\n",
    "result_teacher_forcing = teacher_forcing_generate_tokens(tokenizer, model, batch, cer)\n",
    "\n",
    "# Display results\n",
    "print(\"Teacher Forcing Results:\")\n",
    "print(f\"Decoded Predictions: {result_teacher_forcing['decoded_predictions']}\")\n",
    "print(f\"Decoded References: {result_teacher_forcing['decoded_references']}\")\n",
    "print(f\"CER Score: {result_teacher_forcing['cer_score']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf15f39",
   "metadata": {},
   "source": [
    "## Normal Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795ea87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform forward pass using generate_tokens\n",
    "from utils import generate_tokens\n",
    "\n",
    "# Compute predictions and CER score\n",
    "result_generate_tokens = generate_tokens(tokenizer, model, batch, cer)\n",
    "\n",
    "# Display results\n",
    "print(\"Generate Tokens Results:\")\n",
    "print(f\"Decoded Predictions: {result_generate_tokens['decoded_predictions']}\")\n",
    "print(f\"Decoded References: {result_generate_tokens['decoded_references']}\")\n",
    "print(f\"CER Score: {result_generate_tokens['cer_score']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
