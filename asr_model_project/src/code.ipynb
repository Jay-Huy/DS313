{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c96eaf7b",
   "metadata": {},
   "source": [
    "# Load Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eaa791f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thiếu một hoặc nhiều thư mục con 'train', 'dev', 'test' bên trong: data_aishell\\wav\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "AISHELL_TRANSCRIPT_PATH = \"data_aishell\\\\transcript\\\\aishell_transcript_v0.8.txt\"\n",
    "AISHELL_WAV_ROOT = \"data_aishell\\\\wav\" # Thư mục cha chứa train/dev/test\n",
    "if not os.path.exists(AISHELL_TRANSCRIPT_PATH): exit(f\"Không tìm thấy file transcript tại: {AISHELL_TRANSCRIPT_PATH}\")\n",
    "if not os.path.exists(AISHELL_WAV_ROOT): exit(f\"Không tìm thấy thư mục wav gốc tại: {AISHELL_WAV_ROOT}\")\n",
    "if not all(os.path.isdir(os.path.join(AISHELL_WAV_ROOT, d)) for d in ['train', 'dev', 'test']):\n",
    "        print(f\"Thiếu một hoặc nhiều thư mục con 'train', 'dev', 'test' bên trong: {AISHELL_WAV_ROOT}\")\n",
    "SAMPLE_RATE = 16000; N_MELS = 80; FRAME_LENGTH = 25; FRAME_SHIFT = 10\n",
    "VGG_OUT_CHANNELS = 128; BATCH_SIZE = 4; NUM_WORKERS = 0\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a01f3aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is Windows-SSD\n",
      " Volume Serial Number is FAA0-AAE1\n",
      "\n",
      " Directory of c:\\Users\\huy\\OneDrive\\Desktop\\BTTH-DS313\n",
      "\n",
      "04/09/2025  03:43 PM    <DIR>          .\n",
      "04/08/2025  03:21 PM    <DIR>          ..\n",
      "04/08/2025  07:11 PM    <DIR>          asr_model_project\n",
      "03/18/2025  09:52 AM             6,795 BTTH_Nhom1.ipynb\n",
      "03/23/2025  10:09 AM         1,522,595 Chapter-4-Speech-Synthesis_2.pdf\n",
      "04/08/2025  04:09 PM    <DIR>          data_aishell\n",
      "04/08/2025  03:32 PM            10,482 dataloader_downsampled.py\n",
      "03/23/2025  10:08 AM           207,129 DS313 HomeWork3.pdf\n",
      "04/08/2025  03:47 PM           625,945 qian23_interspeech.pdf\n",
      "04/08/2025  08:17 PM               617 remind.txt\n",
      "               6 File(s)      2,373,563 bytes\n",
      "               4 Dir(s)  30,884,810,752 bytes free\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58eac204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sử dụng thiết bị: cuda\n",
      "\n",
      "--- Khởi tạo Datasets và DataLoaders cho Train, Dev, Test ---\n",
      "\n",
      "=> Đang tạo Dataset cho split: train\n",
      "Initializing Dataset for SPLIT='train' with FBank params: n_mels=80, frame_length=25ms, frame_shift=10ms\n",
      "Đang tìm kiếm file wav trong thư mục của split 'train': data_aishell\\wav\\train\n",
      "Không tìm thấy thư mục con 'train' tại data_aishell\\wav\\train\n",
      "!!! Dataset cho split 'train' bị rỗng. Kiểm tra lại đường dẫn và file.\n",
      "\n",
      "=> Đang tạo Dataset cho split: dev\n",
      "Initializing Dataset for SPLIT='dev' with FBank params: n_mels=80, frame_length=25ms, frame_shift=10ms\n",
      "Đang tìm kiếm file wav trong thư mục của split 'dev': data_aishell\\wav\\dev\n",
      "Không tìm thấy thư mục con 'dev' tại data_aishell\\wav\\dev\n",
      "!!! Dataset cho split 'dev' bị rỗng. Kiểm tra lại đường dẫn và file.\n",
      "\n",
      "=> Đang tạo Dataset cho split: test\n",
      "Initializing Dataset for SPLIT='test' with FBank params: n_mels=80, frame_length=25ms, frame_shift=10ms\n",
      "Đang tìm kiếm file wav trong thư mục của split 'test': data_aishell\\wav\\test\n",
      "Không tìm thấy thư mục con 'test' tại data_aishell\\wav\\test\n",
      "!!! Dataset cho split 'test' bị rỗng. Kiểm tra lại đường dẫn và file.\n"
     ]
    }
   ],
   "source": [
    "from dataloader_downsampled import AISHELL1Dataset, collate_fn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "SAMPLE_RATE = 16000; N_MELS = 80; FRAME_LENGTH = 25; FRAME_SHIFT = 10\n",
    "VGG_OUT_CHANNELS = 128; BATCH_SIZE = 4; NUM_WORKERS = 0\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Sử dụng thiết bị: {device}\")\n",
    "print(\"\\n--- Khởi tạo Datasets và DataLoaders cho Train, Dev, Test ---\")\n",
    "# Tạo Dataset và DataLoader\n",
    "datasets = {}\n",
    "dataloaders = {}\n",
    "for split in ['train', 'dev', 'test']:\n",
    "    print(f\"\\n=> Đang tạo Dataset cho split: {split}\")\n",
    "    datasets[split] = AISHELL1Dataset(\n",
    "        AISHELL_TRANSCRIPT_PATH, AISHELL_WAV_ROOT, split=split,\n",
    "        sample_rate=SAMPLE_RATE, n_mels=N_MELS,\n",
    "        frame_length=FRAME_LENGTH, frame_shift=FRAME_SHIFT\n",
    "    )\n",
    "    if len(datasets[split]) == 0:\n",
    "        print(f\"!!! Dataset cho split '{split}' bị rỗng. Kiểm tra lại đường dẫn và file.\")\n",
    "        continue\n",
    "\n",
    "    print(f\"=> Đang tạo DataLoader cho split: {split}\")\n",
    "    # Shuffle=True cho tập train, False cho dev và test\n",
    "    shuffle_data = (split == 'train')\n",
    "    dataloaders[split] = DataLoader(\n",
    "        datasets[split], batch_size=BATCH_SIZE,\n",
    "        shuffle=shuffle_data, collate_fn=collate_fn,\n",
    "        num_workers=NUM_WORKERS\n",
    "    )\n",
    "    print(f\"Số lượng mẫu trong dataset '{split}': {len(datasets[split])}\")\n",
    "    print(f\"Số lượng batch trong dataloader '{split}': {len(dataloaders[split])}\")\n",
    "\n",
    "if not dataloaders:\n",
    "    exit(\"Không thể tạo bất kỳ DataLoader nào\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec9f6b9",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e69dcf76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\huy\\OneDrive\\Desktop\\BTTH-DS313\\asr_model_project\n"
     ]
    }
   ],
   "source": [
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7d840a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Failed to find CUDA.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\huy\\anaconda3\\envs\\vllm_env\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(149466760, 149466760, 141578888)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.asr_model import ASRModel\n",
    "\n",
    "a, b, c = ASRModel(model_dim=768, mode = 'A').to('cuda'), ASRModel(model_dim=768, mode = 'B').to('cuda'), ASRModel(model_dim=768, mode = 'C').to('cuda')\n",
    "a.params, b.params, c.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af4f9fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "audio_features = torch.randn(10, 20, 768).to('cuda')  # Example input tensor (seq_len, batch_size, acoustic_input_dim)\n",
    "input_ids = torch.randint(0, 21128, (10, 35)).long().to('cuda')\n",
    "attention_mask = torch.ones(10, 35).to('cuda')  # Example attention mask (batch_size, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9baf5385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 35]), torch.Size([10, 20, 768]), torch.Size([10, 35]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids.shape, audio_features.shape, attention_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29d8bff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 35, 21128])\n"
     ]
    }
   ],
   "source": [
    "a_lala = a(input_ids = input_ids,\n",
    "           attention_mask = None,\n",
    "           audio_features = audio_features)\n",
    "print(a_lala.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f260e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 35, 21128])\n"
     ]
    }
   ],
   "source": [
    "b_lala = b(input_ids = input_ids,\n",
    "           attention_mask = None,\n",
    "           audio_features = audio_features)\n",
    "print(b_lala.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e2f1023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 35, 21128])\n"
     ]
    }
   ],
   "source": [
    "c_lala = c(input_ids = input_ids,\n",
    "           attention_mask = None,\n",
    "           audio_features = audio_features)\n",
    "print(c_lala.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vllm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
